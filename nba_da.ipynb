{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Predicting NBA Game Attendance Using Numerous Regression Techniques </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import src.data.datasets as ds\n",
    "import src.data.train_test_split as split\n",
    "import src.features.clustering as clustering\n",
    "import src.features.decomposition as decomposition\n",
    "import src.features.statistical_tests as st\n",
    "import src.initialize_jupyter\n",
    "import src.models.ensemble_models as ensembles\n",
    "import src.models.linear_models as linear_models\n",
    "import src.models.metrics as metrics\n",
    "import src.models.neural_networks as nn\n",
    "import src.models.other_models as other_models\n",
    "import src.visualization.data_exploration as de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "---\n",
    "This data was originally scraped from multiple sources and includes game data since the 1998-1999 season.\\\n",
    "Three datasets have been created for use with many regression techniques:\n",
    "- dataset_1: Game data since January, 2004 that includes Google Trends monthly popularity data per team, filtering of games based on usage of current day stadia, and stadium capacities )\n",
    "- dataset_2: Game data since Fall, 1998 not including popularity, filtering, or capacities\n",
    "- dataset_3: Game data since 1990 including filtering and capacities, but not popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ds.load_datasets()\n",
    "datasets['3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train-test split of dataset and one hot encode categorical features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, train = split.split(datasets['3'])\n",
    "print(\"{} observations in training set\".format(len(X_train), len(X_train.columns)))\n",
    "print(\"{} observations in test set\".format(len(X_test), len(X_test.columns)))\n",
    "print(\"Features: {}:6 numerical, 84 binary categorical; Response: 1 numerical\".format(len(X_test.columns)))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations for data exploration and feature engineering/selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "de.create_all_plots('dataset_3', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition.pca_component_analysis('dataset_3', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition.pca_cv('dataset_3',X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "clustering.elbow_method_kmeans('dataset_3', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "clustering.elbow_method_kmeans('dataset_3', X_train, 25,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clustering.silhouettes('dataset_3', X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further consideration of feature selection through analytic metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.collect_tests('dataset_3', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating subset of dataset_1 based on best guess of important features and preparing it for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_0 = ds.create_dataset_1_1(dataset_1)\n",
    "print(\"dataset_1_1 contains: {} observations; {} features: 4 numerical, 3 multiclass categorical, 2 binary categorical; 1 Response\".format(len(dataset_1_1), len(dataset_1_1.columns)-1))\n",
    "X_train_0, X_test_1, y_train_1, y_test_1, train_1 = split.split(dataset_1_1)\n",
    "print(\"After split contains:\")\n",
    "print(\"{} observations in training set\".format(len(X_train_1), len(X_train_1.columns)))\n",
    "print(\"{} observations in test set\".format(len(X_test_1), len(X_test_1.columns)))\n",
    "print(\"28 features: 4 numerical, 24 binary categorical; 1 Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1, train_1 = split.split(dataset_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with linear models that generally have simpler hyperparameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_statistics = linear_models.collect_statistics('dataset_3', X_train, X_test, y_train, y_test).reset_index()\n",
    "                                                        \n",
    "# display(linear_statistics.sort_values(['Mean Absolute Error'])['index', Mean Absolute Error'].head())\n",
    "# display(linear_statistics.sort_values(['R^2'], ascending = False)['index', 'R^2'].head())\n",
    "# linear_statistics.sort_values(['Root Mean Square Error'])['index', 'Root Mean Square Error'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_statistics = linear_statistics.reset_index()\n",
    "linear_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, ensemble methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_jobs=-1, random_state = 18, criterion = 'mae').fit(X_train, y_train).predict(X_test)\n",
    "rf = metrics.apply_metrics('dataset_3: {}'.format('rf'), y_test, rf.ravel())\n",
    "ab = AdaBoostRegressor(n_jobs = -1, random_state = 18).fit(X_train, y_train).predict(X_test)\n",
    "ab = metrics.apply_metrics('dataset_3: {}'.format('ab'), y_test, ab.ravel())\n",
    "gbr = GradientBoostingRegressor(random_state = 18).fit(X_train, y_train).predict(X_test)\n",
    "gbr = metrics.apply_metrics('dataset_3: {}'.format('gbr'), y_test, gbr.ravel())\n",
    "et =  ExtraTreesRegressor(n_jobs = -1, random_state = 18)\n",
    "et = metrics.apply_metrics('dataset_3: {}'.format('et'), y_test, et.ravel())\n",
    "df = pd.concat([rf,ab,gbr,et], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cv = ensembles.random_forest_grid_cv(X_train, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cv_df = pd.DataFrame.from_dict(random_forest_cv.cv_results_)[['params', 'rank_test_R^2','mean_test_R^2','rank_test_Explained Variance Score', 'mean_test_Explained Variance Score',\n",
    "                                                      'rank_test_Mean Absolute Error', 'mean_test_Mean Absolute Error', 'rank_test_Root Mean Square Error',\n",
    "                                                      'mean_test_Root Mean Square Error','rank_test_Mean Absolute Percent Error',\n",
    "                                                      'mean_test_Mean Absolute Percent Error']].sort_values(['rank_test_Mean Absolute Error', \n",
    "                                                                                                        'rank_test_R^2', \n",
    "                                                                                                        'rank_test_Root Mean Square Error',\n",
    "                                                                                                        'rank_test_Explained Variance Score',\n",
    "                                                                                                        'rank_test_Mean Absolute Percent Error'])\n",
    "# random_forest_cv_df\n",
    "random_forest_cv_df.head(10)['params'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = Path().resolve().joinpath('models', 'cross_validation_outcomes', '{}.csv'.format('random_forest_random_cv_1'))\n",
    "random_forest_cv_df.to_csv(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_cv = ensembles.adaboost_randomized_cv(X_train, y_train, n_iter = 25, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_by_all_rank = pd.DataFrame.from_dict(adaboost_cv.cv_results_)[['params', 'rank_test_R^2', 'rank_test_Explained Variance Score', \n",
    "                                                  'rank_test_Mean Absolute Error', 'rank_test_Root Mean Square Error',\n",
    "                                                 'rank_test_Mean Absolute Percent Error']].sort_values(['rank_test_Mean Absolute Error', \n",
    "                                                                                                        'rank_test_R^2', \n",
    "                                                                                                        'rank_test_Explained Variance Score',                                                                                                    \n",
    "                                                                                                        'rank_test_Root Mean Square Error',\n",
    "                                                                                                        'rank_test_Mean Absolute Percent Error']).head(10)['params'].values\n",
    "top_ten_by_all_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_cv = ensembles.gradient_boosting_randomized_cv(X_train, y_train, n_iter = 25, cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_cv_boosting_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_by_all_rank = pd.DataFrame.from_dict(gradient_boosting_cv.cv_results_)[['params', 'rank_test_R^2', 'rank_test_Explained Variance Score', \n",
    "                                                  'rank_test_Mean Absolute Error', 'rank_test_Root Mean Square Error',\n",
    "                                                 'rank_test_Mean Absolute Percent Error']].sort_values(['rank_test_Mean Absolute Error', \n",
    "                                                                                                        'rank_test_Explained Variance Score',\n",
    "                                                                                                        'rank_test_R^2', \n",
    "                                                                                                        'rank_test_Root Mean Square Error',\n",
    "                                                                                                        'rank_test_Mean Absolute Percent Error']).head(10)['params'].values\n",
    "top_ten_by_all_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_cv = ensembles.extra_trees_randomized_cv(X_train, y_train, n_iter = 25, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_by_all_rank = pd.DataFrame.from_dict(extra_trees_cv.cv_results_)[['params', 'rank_test_R^2', 'rank_test_Explained Variance Score', \n",
    "                                                  'rank_test_Mean Absolute Error', 'rank_test_Root Mean Square Error',\n",
    "                                                 'rank_test_Mean Absolute Percent Error']].sort_values(['rank_test_Mean Absolute Error', \n",
    "                                                                                                        'rank_test_Explained Variance Score',\n",
    "                                                                                                        'rank_test_R^2', \n",
    "                                                                                                        'rank_test_Root Mean Square Error',\n",
    "                                                                                                        'rank_test_Mean Absolute Percent Error']).head(10)['params'].values\n",
    "top_ten_by_all_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors_randomized = other_models.k_neighbors_randomized_cv(X_train, y_train, 25, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(k_neighbors_randomized.cv_results_)\n",
    "df[['params', 'mean_test_R^2', 'rank_test_R^2', 'rank_test_Explained Variance Score', \n",
    "                                                  'rank_test_Mean Absolute Error', 'rank_test_Root Mean Square Error',\n",
    "                                                 'rank_test_Mean Absolute Percent Error']].sort_values(['rank_test_Mean Absolute Error', \n",
    "                                                                                                        'rank_test_Explained Variance Score',\n",
    "                                                                                                        'rank_test_R^2', \n",
    "                                                                                                        'rank_test_Root Mean Square Error',\n",
    "                                                                                                        'rank_test_Mean Absolute Percent Error'])[['params']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_cv = nn.single_layer_network_grid_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_statistics.sort_values(['R^2'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nn.single_layer_network('dataset_3',X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.apply_metrics('30', y_test, preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "for i in np.arange(5,131,5):\n",
    "    preds = nn.single_layer_network(X_train, X_test, y_train, i)\n",
    "    preds = metrics.apply_metrics('dataset_3: {} neurons'.format(i), y_test, preds.ravel())\n",
    "    df = pd.concat([df, preds], axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = Path().resolve().joinpath('models', 'cross_validation_outcomes', '{}.csv'.format('single_layer_network_neuron_cv'))\n",
    "df.to_csv(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nn.single_layer_network('dataset_3',X_train, X_test, y_train, 10)\n",
    "preds = metrics.apply_metrics('dataset_3', y_test, preds.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cv = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ieor_142_project] *",
   "language": "python",
   "name": "conda-env-ieor_142_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
